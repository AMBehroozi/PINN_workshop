{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cic3zzNOPuDt",
        "outputId": "fee2c9a5-dbab-4408-af9b-b616fb5f8a17"
      },
      "outputs": [],
      "source": [
        "import math\n",
        "from smt.sampling_methods import LHS\n",
        "import torch              \n",
        "import torch.nn as nn                                   \n",
        "from collections import OrderedDict\n",
        "import numpy as np\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3_UTdJuqPuDw",
        "outputId": "cdd0c6ff-59ec-40f9-e31d-52dfb79f3b7f"
      },
      "outputs": [],
      "source": [
        "# CUDA GPU selection\n",
        "if torch.cuda.is_available():\n",
        "    device = torch.device('cuda:2')\n",
        "else:\n",
        "    device = torch.device('cpu')\n",
        "\n",
        "print(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XwWYvLP0PuDy"
      },
      "outputs": [],
      "source": [
        "# Definition of Deep Neural Network Architecture\n",
        "class DNNModel(torch.nn.Module):\n",
        "    def __init__(\n",
        "        self,\n",
        "        input_size,\n",
        "        hidden_size,\n",
        "        output_size,\n",
        "        depth,\n",
        "        act=torch.nn.Tanh,\n",
        "        init_mode='xavier'\n",
        "    ):\n",
        "        super(DNNModel, self).__init__()\n",
        "        \n",
        "        layers = [('input', torch.nn.Linear(input_size, hidden_size))]\n",
        "        layers.append(('input_activation', act()))\n",
        "        for i in range(depth): \n",
        "            layers.append(\n",
        "                ('hidden_%d' % i, torch.nn.Linear(hidden_size, hidden_size))\n",
        "            )\n",
        "            layers.append(('activation_%d' % i, act()))\n",
        "        layers.append(('output', torch.nn.Linear(hidden_size, output_size)))\n",
        "\n",
        "        layerDict = OrderedDict(layers)\n",
        "        self.layers = torch.nn.Sequential(layerDict)\n",
        "\n",
        "        if init_mode == 'xavier':\n",
        "          for m in self.modules():                \n",
        "              if isinstance(m, nn.Linear):\n",
        "                  size = m.weight.size()\n",
        "                  fan_out = size[0] # Number of rows\n",
        "                  fan_in = size[1] # Number of columns\n",
        "                  variance = math.sqrt(2.0/(fan_in+fan_out))\n",
        "                  m.weight.data.normal_(0.0, variance)\n",
        "                  if m.bias is not None:\n",
        "                      m.bias.data.normal_(0, variance)            \n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.layers(x)\n",
        "        return out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zxLlAHyjPuD0"
      },
      "outputs": [],
      "source": [
        "# Defintion of Physics infomed neural network\n",
        "class PINN():\n",
        "    def __init__(self):\n",
        "        \n",
        "        self.model = DNNModel(\n",
        "            input_size=2,\n",
        "            hidden_size=50,\n",
        "            output_size=5,\n",
        "            depth=8,\n",
        "            act=torch.nn.Tanh,\n",
        "            init_mode='xavier'\n",
        "            ).to(device)\n",
        "        \n",
        "        self.dx = 0.01\n",
        "        self.dy = 0.005\n",
        "        self.nx = 500\n",
        "        self.ny = 200\n",
        "        self.rho=1.1644        \n",
        "        self.mu=0.005\n",
        "        \n",
        "        x = torch.arange(0, 5 + self.dx, self.dx)\n",
        "        y = torch.arange(0, 1 + self.dy, self.dy)\n",
        "\n",
        "        xlimits = np.array([[0.001, 0.0], [4.999, 0.0]])\n",
        "        sampling = LHS(xlimits=xlimits)        \n",
        "        xb = sampling(self.nx)\n",
        "\n",
        "        xb=torch.tensor(xb,dtype=torch.float32)        \n",
        "\n",
        "        xlimits = np.array([[0.0, 0.001], [0.0, 0.999]])\n",
        "        sampling = LHS(xlimits=xlimits)        \n",
        "        yb = sampling(self.ny)\n",
        "\n",
        "        yb=torch.tensor(yb,dtype=torch.float32)        \n",
        "        \n",
        "        # Geometry and Discretization training data\n",
        "        self.inlet=torch.stack(torch.meshgrid(torch.zeros(1), y, indexing='ij')).reshape(2, -1).T\n",
        "        self.outlet=torch.stack(torch.meshgrid(torch.ones(1)*5, y, indexing='ij')).reshape(2, -1).T\n",
        "\n",
        "        bc1 = torch.stack(torch.meshgrid(x, torch.zeros(1), indexing='ij')).reshape(2, -1).T\n",
        "        bc2 = torch.stack(torch.meshgrid(x, torch.ones(1), indexing='ij')).reshape(2, -1).T\n",
        "\n",
        "        self.id = torch.stack(torch.meshgrid(xb[:,1], yb[:,1], indexing='ij')).reshape(2, -1).T\n",
        "        self.bc = torch.cat([bc1, bc2])\n",
        "\n",
        "        u_inlet = torch.ones(len(self.inlet))\n",
        "        v_inlet = torch.zeros(len(self.inlet))\n",
        "        \n",
        "        v_outlet = torch.zeros(len(self.outlet))\n",
        "        p_outlet = torch.zeros(len(self.outlet))\n",
        "        \n",
        "        u_bc1 = torch.zeros(len(bc1))\n",
        "        v_bc1 = torch.zeros(len(bc1))\n",
        "\n",
        "        u_bc2 = torch.zeros(len(bc2))\n",
        "        v_bc2 = torch.zeros(len(bc2))           \n",
        "\n",
        "        self.uv_inlet = torch.stack((u_inlet, v_inlet)).reshape(2, -1).T\n",
        "        self.vp_outlet = torch.stack((v_outlet, p_outlet)).reshape(2, -1).T\n",
        "\n",
        "        uv_bc1 = torch.stack((u_bc1, v_bc1)).reshape(2, -1).T\n",
        "        uv_bc2 = torch.stack((u_bc2, v_bc2)).reshape(2, -1).T\n",
        "\n",
        "        self.uv_bc = torch.cat([uv_bc1, uv_bc2])\n",
        "\n",
        "        self.pde_sol=torch.zeros(len(self.id))\n",
        "\n",
        "        self.y_train = torch.cat([self.uv_inlet, uv_bc1, uv_bc2, self.vp_outlet])\n",
        "        self.y_train = self.y_train.unsqueeze(1)\n",
        "        \n",
        "        self.id = self.id.to(device)\n",
        "        self.bc = self.bc.to(device)\n",
        "        self.inlet = self.inlet.to(device)\n",
        "        self.outlet = self.outlet.to(device)\n",
        "        self.uv_inlet = self.uv_inlet.to(device)\n",
        "        self.vp_outlet = self.vp_outlet.to(device)\n",
        "        self.pde_sol = self.pde_sol.to(device)\n",
        "        self.uv_bc = self.uv_bc.to(device)\n",
        "        self.y_train = self.y_train.to(device)\n",
        "        self.id.requires_grad = True\n",
        "        self.bc.requires_grad = True\n",
        "        self.inlet.requires_grad = True\n",
        "        self.outlet.requires_grad = True\n",
        "        \n",
        "        self.criterion = torch.nn.MSELoss()\n",
        "        self.iter = 1\n",
        "        \n",
        "        self.optimizer = torch.optim.LBFGS(\n",
        "            self.model.parameters(), \n",
        "            lr=0.001, \n",
        "            max_iter=100000, \n",
        "            max_eval=100000, \n",
        "            history_size=50,\n",
        "            tolerance_grad=1e-5, \n",
        "            tolerance_change=1.0 * np.finfo(float).eps\n",
        "            )\n",
        "        \n",
        "        self.adam = torch.optim.Adam(self.model.parameters(), lr=0.0001)\n",
        "\n",
        "    #Definition of Bounday and Navier-stokes residual loss   \n",
        "    def loss_func(self):\n",
        "        self.optimizer.zero_grad()\n",
        "        \n",
        "        y_inlet = self.model(self.inlet)        \n",
        "        dpsi_dX = torch.autograd.grad(inputs=self.inlet, outputs=y_inlet[:,0], grad_outputs=torch.ones_like(y_inlet[:,0]), retain_graph=True, create_graph=True)[0]\n",
        "        dpsi_dx = -1*dpsi_dX[:, 0] \n",
        "        dpsi_dy = dpsi_dX[:, 1]       \n",
        "        loss_inlet = self.criterion(dpsi_dy, self.uv_inlet[:,0])+self.criterion(dpsi_dx, self.uv_inlet[:,1])\n",
        "            \n",
        "        y_bc = self.model(self.bc)\n",
        "        dpsi_dX = torch.autograd.grad(inputs=self.bc, outputs=y_bc[:,0], grad_outputs=torch.ones_like(y_bc[:,0]), retain_graph=True, create_graph=True)[0]\n",
        "        dpsi_dx = -1*dpsi_dX[:, 0] \n",
        "        dpsi_dy = dpsi_dX[:, 1]\n",
        "        loss_bc = self.criterion(dpsi_dy, self.uv_bc[:,0])+self.criterion(dpsi_dx, self.uv_bc[:,1])\n",
        "\n",
        "        y_outlet = self.model(self.outlet)\n",
        "        loss_outlet = self.criterion(y_outlet[:,1], self.vp_outlet[:,1])\n",
        "        \n",
        "        loss_b=loss_inlet+loss_bc+loss_outlet\n",
        "\n",
        "        y_id = self.model(self.id)\n",
        "        dpsi_dX = torch.autograd.grad(inputs=self.id, outputs=y_id[:,0], grad_outputs=torch.ones_like(y_id[:,0]), retain_graph=True, create_graph=True)[0]\n",
        "        dpsi_dx = -1*dpsi_dX[:, 0] \n",
        "        dpsi_dy = dpsi_dX[:, 1]\n",
        "        dpsi_dXX = torch.autograd.grad(inputs=self.id, outputs=dpsi_dy, grad_outputs=torch.ones_like(dpsi_dy), retain_graph=True, create_graph=True)[0]\n",
        "        dpsi_dyx = dpsi_dXX[:, 0] \n",
        "        dpsi_dyy = dpsi_dXX[:, 1]\n",
        "        dpsi_dYY = torch.autograd.grad(inputs=self.id, outputs=dpsi_dx, grad_outputs=torch.ones_like(dpsi_dx), retain_graph=True, create_graph=True)[0]\n",
        "        dpsi_dxx = dpsi_dYY[:, 0] \n",
        "        dpsi_dxy = dpsi_dYY[:, 1]\n",
        "        dsxx_dX = torch.autograd.grad(inputs=self.id, outputs=y_id[:,2], grad_outputs=torch.ones_like(y_id[:,2]), retain_graph=True, create_graph=True)[0]\n",
        "        dsxx_dx = dsxx_dX[:,0]\n",
        "        dsyy_dX = torch.autograd.grad(inputs=self.id, outputs=y_id[:,3], grad_outputs=torch.ones_like(y_id[:,3]), retain_graph=True, create_graph=True)[0]\n",
        "        dsyy_dy = dsyy_dX[:,1]\n",
        "        dsxy_dX = torch.autograd.grad(inputs=self.id, outputs=y_id[:,4], grad_outputs=torch.ones_like(y_id[:,4]), retain_graph=True, create_graph=True)[0]\n",
        "        dsxy_dx = dsxy_dX[:, 0] \n",
        "        dsxy_dy = dsxy_dX[:, 1]       \n",
        "\n",
        "        loss_u =  self.rho*(dpsi_dy*dpsi_dyx+dpsi_dx*dpsi_dyy)-(dsxx_dx+dsxy_dy)\n",
        "        loss_v =  self.rho*(dpsi_dy*dpsi_dxx+dpsi_dx*dpsi_dxy)-(dsxy_dx+dsyy_dy)\n",
        "        loss_m =  -1*y_id[:,1]+2*self.mu*(dpsi_dyx+dpsi_dxy)-(y_id[:,2]+y_id[:,3])/2+self.mu*(dpsi_dyy+dpsi_dxx)-y_id[:,4]      \n",
        "\n",
        "\n",
        "        loss_ns = self.criterion(loss_u+loss_v+loss_m, self.pde_sol)\n",
        "        b=1.8\n",
        "        loss = b*loss_b+loss_ns \n",
        "        loss.backward()\n",
        "        if self.iter % 20 == 0: \n",
        "            print(self.iter, loss.item())       \n",
        "            \n",
        "        self.iter = self.iter + 1        \n",
        "        return loss\n",
        "    \n",
        "    def train(self):\n",
        "        for i in range(20000):\n",
        "            self.adam.step(self.loss_func)\n",
        "        self.optimizer.step(self.loss_func)\n",
        "   "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6Zw35q0SPuD4",
        "outputId": "26e43ae1-6150-49ff-eef3-2bb0dc8fa494"
      },
      "outputs": [],
      "source": [
        "net = PINN()\n",
        "net.train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "eVjznID1CH62",
        "outputId": "607c8b83-d6b2-4e64-d486-9460eb3bf5b9"
      },
      "outputs": [],
      "source": [
        "#Saving the trained model\n",
        "torch.save(net, './channel_lhs_8l_0.1m_0.001_0.0001.t7')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        },
        "id": "eDP5NHnSPuD5",
        "outputId": "5c022435-f4bd-4ddb-c61d-6d69ff0bd9f8"
      },
      "outputs": [],
      "source": [
        "#Post processing for results analysis\n",
        "\n",
        "x = torch.arange(0, 5 + 0.01 , 0.01)\n",
        "y = torch.arange(0, 1 +0.005, 0.005)\n",
        "outlet= torch.stack(torch.meshgrid(x, y)).reshape(2, -1).T\n",
        "outlet = outlet.to(net.outlet.device)\n",
        "outlet.requires_grad = True\n",
        "\n",
        "model = net.model\n",
        "model.eval()\n",
        "\n",
        "y_pred = model(outlet)\n",
        "dpsi_dX = torch.autograd.grad(inputs=outlet, outputs=y_pred[:,0], grad_outputs=torch.ones_like(y_pred[:,0]), retain_graph=True, create_graph=True)[0]\n",
        "dpsi_dX[:, 0] = -1*dpsi_dX[:, 0]\n",
        "\n",
        "fld=torch.cat([outlet, dpsi_dX ,y_pred], 1)\n",
        "fld=fld.detach().cpu().numpy()\n",
        "\n",
        "np.savetxt('output.dat', fld)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3.9.2rc1 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    },
    "vscode": {
      "interpreter": {
        "hash": "52634da84371cba311ea128a5ea7cdc41ff074b781779e754b270ff9f8153cee"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
